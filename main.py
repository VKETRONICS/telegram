from fastapi import FastAPI, Request
import httpx
import os
from dotenv import load_dotenv
import openai

load_dotenv()

app = FastAPI()

BOT_TOKEN = os.getenv("BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
TELEGRAM_API_URL = f"https://api.telegram.org/bot{BOT_TOKEN}"

user_states = {}
dialog_history = {}

@app.post("/webhook")
async def telegram_webhook(request: Request):
    data = await request.json()

    if "message" in data:
        message = data["message"]
        chat_id = message.get("chat", {}).get("id")
        text = message.get("text", "")
        print(f"ÐŸÐžÐ›Ð£Ð§Ð•ÐÐž Ð¡ÐžÐžÐ‘Ð©Ð•ÐÐ˜Ð•: {text}")

        if chat_id and text:
            if text == "/start" or text == "/menu":
                user_states[chat_id] = "menu"
                dialog_history.pop(chat_id, None)
                await send_main_menu(chat_id)

            elif text == "ðŸ“¦ ÐšÐ°Ñ‚Ð°Ð»Ð¾Ð³":
                await send_catalog_menu(chat_id)

            elif text == "â„¹ï¸ Ðž Ð½Ð°Ñ":
                about_text = (
                    "ðŸ”§ ETRONICS â€” Ð²Ð°Ñˆ Ð¿Ñ€Ð¾Ð²Ð¾Ð´Ð½Ð¸Ðº Ð² Ð¼Ð¸Ñ€Ðµ ÑÐ»ÐµÐºÑ‚Ñ€Ð¾Ð½Ð¸ÐºÐ¸!\n\n"
                    "ðŸ’» ÐœÑ‹ ÑÐ¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ ÐºÐ¾Ð¼Ð¿ÑŒÑŽÑ‚ÐµÑ€Ñ‹ Ð»ÑŽÐ±Ð¾Ð¹ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸ Ð½Ð° Ð·Ð°ÐºÐ°Ð·:\n" 
                    "â€¢ ðŸŽ® Ð˜Ð³Ñ€Ð¾Ð²Ñ‹Ðµ ÑÐ±Ð¾Ñ€ÐºÐ¸\n"
                    "â€¢ ðŸ¢ ÐŸÐš Ð´Ð»Ñ ÑƒÑ‡ÐµÐ±Ñ‹, Ð¾Ñ„Ð¸ÑÐ° Ð¸ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹\n" 
                    "â€¢ ðŸ’¼ Ð¡Ñ‚Ð°Ð½Ñ†Ð¸Ð¸ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ñ„ÐµÑÑÐ¸Ð¾Ð½Ð°Ð»Ð¾Ð² Ð¸ Ñ‚Ð²Ð¾Ñ€Ñ‡ÐµÑÑ‚Ð²Ð°\n\n" 
                    "ðŸ–¥ Ð’ÑÐµÐ³Ð´Ð° Ð² Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ð¸:\n" 
                    "â€¢ ðŸ’» ÐÐ¾ÑƒÑ‚Ð±ÑƒÐºÐ¸ â€” Ð¾Ñ‚ Ð±ÑŽÐ´Ð¶ÐµÑ‚Ð½Ñ‹Ñ… Ð´Ð¾ Ð¿Ñ€ÐµÐ¼Ð¸ÑƒÐ¼\n"
                    "â€¢ ðŸŽ§ ÐÐºÑÐµÑÑÑƒÐ°Ñ€Ñ‹ â€” Ð¼Ñ‹ÑˆÐ¸, ÐºÐ»Ð°Ð²Ð¸Ð°Ñ‚ÑƒÑ€Ñ‹, Ð½Ð°ÑƒÑˆÐ½Ð¸ÐºÐ¸, SSD Ð¸ Ð´Ñ€ÑƒÐ³Ð¾Ðµ\n\n"
                    "ðŸ“¦ ÐŸÐ¾Ñ‡ÐµÐ¼Ñƒ Ð²Ñ‹Ð±Ð¸Ñ€Ð°ÑŽÑ‚ Ð½Ð°Ñ:\n"
                    "â€¢ ðŸ§‘â€ðŸ’» Ð˜Ð½Ð´Ð¸Ð²Ð¸Ð´ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¿Ð¾Ð´Ñ…Ð¾Ð´\n"
                    "â€¢ âœ… ÐšÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾ ÐºÐ¾Ð¼Ð¿Ð»ÐµÐºÑ‚ÑƒÑŽÑ‰Ð¸Ñ…\n"
                    "â€¢ ðŸšš Ð‘Ñ‹ÑÑ‚Ñ€Ð°Ñ Ð´Ð¾ÑÑ‚Ð°Ð²ÐºÐ°\n" 
                    "â€¢ ðŸ’¬ ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð¾Ð±Ð¾Ñ€ÑƒÐ´Ð¾Ð²Ð°Ð½Ð¸Ñ, Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ° Ð¸ ÐºÐ¾Ð½ÑÑƒÐ»ÑŒÑ‚Ð°Ñ†Ð¸Ð¸\n\n" 
                    "ðŸ“² Ð¡Ð²ÑÐ¶Ð¸Ñ‚ÐµÑÑŒ Ñ Ð½Ð°Ð¼Ð¸:"
                )
                reply_markup = {
                    "keyboard": [
                        [{"text": "ðŸ“ž ÐšÐ¾Ð½Ñ‚Ð°ÐºÑ‚Ñ‹"}],
                        [{"text": "ðŸ“‹ ÐœÐµÐ½ÑŽ"}]
                    ],
                    "resize_keyboard": True
                }
                await send_message(chat_id, about_text, reply_markup)

            elif text == "ðŸ“ž ÐšÐ¾Ð½Ñ‚Ð°ÐºÑ‚Ñ‹":
                await send_message(chat_id, "ðŸ“§ support@etronics.pro\nðŸ“± @etronics_support")

            elif text == "â“ ÐŸÐ¾Ð¼Ð¾Ñ‰ÑŒ":
                user_states[chat_id] = "gpt"
                dialog_history[chat_id] = []
                await send_message(chat_id, "ðŸ§  Ð¯ Ð³Ð¾Ñ‚Ð¾Ð² Ð¿Ð¾Ð¼Ð¾Ñ‡ÑŒ! ÐÐ°Ð¿Ð¸ÑˆÐ¸Ñ‚Ðµ ÑÐ²Ð¾Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ. Ð”Ð»Ñ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‚Ð° Ð½Ð°Ð¶Ð¼Ð¸Ñ‚Ðµ ðŸ“‹ ÐœÐµÐ½ÑŽ", {
                    "keyboard": [[{"text": "ðŸ“‹ ÐœÐµÐ½ÑŽ"}]],
                    "resize_keyboard": True
                })

            elif user_states.get(chat_id) == "gpt":
                dialog_history.setdefault(chat_id, [])
                dialog_history[chat_id].append({"role": "user", "content": text})
                gpt_response = await ask_gpt(dialog_history[chat_id])
                dialog_history[chat_id].append({"role": "assistant", "content": gpt_response})
                await send_message(chat_id, gpt_response, {
                    "keyboard": [[{"text": "ðŸ“‹ ÐœÐµÐ½ÑŽ"}]],
                    "resize_keyboard": True
                })

    elif "callback_query" in data:
        callback = data["callback_query"]
        chat_id = callback["message"]["chat"]["id"]
        message_id = callback["message"]["message_id"]
        data_value = callback.get("data", "")
        print(f"CALLBACK: {data_value}")

        if data_value == "laptops":
            sub_markup = {
                "inline_keyboard": [
                    [{"text": "ðŸŽ® Ð˜Ð³Ñ€Ð¾Ð²Ñ‹Ðµ Ð½Ð¾ÑƒÑ‚Ð±ÑƒÐºÐ¸", "callback_data": "laptop_gaming"}],
                    [{"text": "ðŸ‘¨â€ðŸŽ“ Ð”Ð»Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ð¸ ÑƒÑ‡Ñ‘Ð±Ñ‹", "callback_data": "laptop_workstudy"}],
                    [{"text": "â¬…ï¸ ÐÐ°Ð·Ð°Ð´", "callback_data": "catalog"}]
                ]
            }
            await send_catalog_update(chat_id, message_id, "ðŸ’» Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¿Ð¾Ð´ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸ÑŽ:", sub_markup)

        elif data_value == "laptop_workstudy":
            sub_markup = {
                "inline_keyboard": [
                    [{"text": "ðŸ’» 12â€“14", "callback_data": "work_12_14"}],
                    [{"text": "ðŸ’» 15â€“16", "callback_data": "work_15_16"}],
                    [{"text": "ðŸ’» 17â€“18", "callback_data": "work_17_18"}],
                    [{"text": "ðŸ“‹ Ð’ÐµÑÑŒ ÑÐ¿Ð¸ÑÐ¾Ðº (Ð²ÑÐµ Ñ€Ð°Ð·Ð¼ÐµÑ€Ñ‹)", "callback_data": "work_full_list"}],
                    [{"text": "â¬…ï¸ ÐÐ°Ð·Ð°Ð´", "callback_data": "laptops"}]
                ]
            }
            await send_catalog_update(chat_id, message_id, "ðŸ‘¨â€ðŸŽ“ Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ñ€Ð°Ð·Ð¼ÐµÑ€ Ð½Ð¾ÑƒÑ‚Ð±ÑƒÐºÐ°:", sub_markup)

        elif data_value == "phones":
            sub_markup = {
                "inline_keyboard": [
                    [{"text": "ðŸ“± Ð¡Ð¼Ð°Ñ€Ñ‚Ñ„Ð¾Ð½Ñ‹", "callback_data": "phones_smart"}],
                    [{"text": "ðŸ“ž ÐšÐ½Ð¾Ð¿Ð¾Ñ‡Ð½Ñ‹Ðµ Ñ‚ÐµÐ»ÐµÑ„Ð¾Ð½Ñ‹", "callback_data": "phones_button"}],
                    [{"text": "â¬…ï¸ ÐÐ°Ð·Ð°Ð´", "callback_data": "catalog"}]
                ]
            }
            await send_catalog_update(chat_id, message_id, "ðŸ“± Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ñ‚Ð¸Ð¿ Ñ‚ÐµÐ»ÐµÑ„Ð¾Ð½Ð°:", sub_markup)

        elif data_value == "catalog":
            reply_markup = {
                "inline_keyboard": [
                    [{"text": "ðŸ’» ÐÐ¾ÑƒÑ‚Ð±ÑƒÐºÐ¸", "callback_data": "laptops"}],
                    [{"text": "ðŸ“± Ð¢ÐµÐ»ÐµÑ„Ð¾Ð½Ñ‹", "callback_data": "phones"}],
                    [{"text": "ðŸ–¥ ÐšÐ¾Ð¼Ð¿Ð»ÐµÐºÑ‚ÑƒÑŽÑ‰Ð¸Ðµ", "callback_data": "components"}]
                ]
            }
            await send_catalog_update(chat_id, message_id, "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸ÑŽ Ñ‚Ð¾Ð²Ð°Ñ€Ð°:", reply_markup)

    return {"ok": True}


async def send_main_menu(chat_id: int):
    reply_markup = {
        "keyboard": [
            [{"text": "ðŸ“¦ ÐšÐ°Ñ‚Ð°Ð»Ð¾Ð³"}],
            [{"text": "â„¹ï¸ Ðž Ð½Ð°Ñ"}, {"text": "ðŸ“ž ÐšÐ¾Ð½Ñ‚Ð°ÐºÑ‚Ñ‹"}],
            [{"text": "â“ ÐŸÐ¾Ð¼Ð¾Ñ‰ÑŒ"}]
        ],
        "resize_keyboard": True
    }
    await send_message(chat_id, "ðŸŽ‰ Ð”Ð¾Ð±Ñ€Ð¾ Ð¿Ð¾Ð¶Ð°Ð»Ð¾Ð²Ð°Ñ‚ÑŒ Ð² ETRONICS STORE!\n\nÐ’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÑƒÑŽÑ‰Ð¸Ð¹ Ð²Ð°Ñ Ñ€Ð°Ð·Ð´ÐµÐ» Ð½Ð¸Ð¶Ðµ ðŸ‘‡", reply_markup)


async def send_catalog_menu(chat_id: int):
    reply_markup = {
        "inline_keyboard": [
            [{"text": "ðŸ’» ÐÐ¾ÑƒÑ‚Ð±ÑƒÐºÐ¸", "callback_data": "laptops"}],
            [{"text": "ðŸ“± Ð¢ÐµÐ»ÐµÑ„Ð¾Ð½Ñ‹", "callback_data": "phones"}],
            [{"text": "ðŸ–¥ ÐšÐ¾Ð¼Ð¿Ð»ÐµÐºÑ‚ÑƒÑŽÑ‰Ð¸Ðµ", "callback_data": "components"}]
        ]
    }
    await send_message(chat_id, "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸ÑŽ Ñ‚Ð¾Ð²Ð°Ñ€Ð°:", reply_markup)


async def send_message(chat_id: int, text: str, reply_markup=None):
    payload = {
        "chat_id": chat_id,
        "text": text
    }
    if reply_markup is not None:
        payload["reply_markup"] = reply_markup

    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(f"{TELEGRAM_API_URL}/sendMessage", json=payload)
            print(f"ÐžÐ¢ÐŸÐ ÐÐ’ÐšÐ Ð¡ÐžÐžÐ‘Ð©Ð•ÐÐ˜Ð¯: {response.status_code} | {response.text}")
    except Exception as e:
        print(f"ÐžÐ¨Ð˜Ð‘ÐšÐ ÐŸÐ Ð˜ ÐžÐ¢ÐŸÐ ÐÐ’ÐšÐ• Ð¡ÐžÐžÐ‘Ð©Ð•ÐÐ˜Ð¯: {e}")


async def send_catalog_update(chat_id: int, message_id: int, text: str, reply_markup: dict):
    async with httpx.AsyncClient() as client:
        response = await client.post(
            f"{TELEGRAM_API_URL}/editMessageText",
            json={
                "chat_id": chat_id,
                "message_id": message_id,
                "text": text,
                "reply_markup": reply_markup
            }
        )
        print(f"ÐžÐ‘ÐÐžÐ’Ð›Ð•ÐÐ˜Ð• ÐšÐÐ¢ÐÐ›ÐžÐ“Ð: {response.status_code} | {response.text}")


async def ask_gpt(messages: list) -> str:
    try:
        client = openai.OpenAI(api_key=OPENAI_API_KEY)
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=messages,
            max_tokens=300,
            temperature=0.7
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"GPT ERROR: {e}")
        return "ÐŸÑ€Ð¾Ð¸Ð·Ð¾ÑˆÐ»Ð° Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ð¸ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð¾Ñ‚ Ð˜Ð˜ ðŸ˜”"
